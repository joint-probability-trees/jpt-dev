{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Joint Probability Trees (JPTs) offer a rich representation for joint probability distributions.\n",
    "This tutorial will guide you through the basic functionalities of JPTs.\n",
    "To install the package, clone the repository and run the setup file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "$ git clone git@spritinio.de:jpt-dev\n",
    "$ cd jpt-dev\n",
    "$ python src/setup.py install"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "or install the package via pip when provided the wheel file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "$ pip install jpt-0.1.0-cp38-cp38-linux_x86_64.whl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The guiding dataset for this tutorial will be the MNIST Handwritten Digit Recognition dataset.\n",
    "In this dataset 8x8 greyscale pictures are mapped to the digit (0-9) that is represented by that picture.\n",
    "To load the dataset, execute the cell below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "mnist = load_digits()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now visualize some numbers stored in the dataset to get a feel for it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAEICAYAAACHyrIWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANZ0lEQVR4nO3df4xl5V3H8fenyzaU30uLSHZp+SGSoKZQCFppsAWqtEVqomzAgFo1i5pWiNVCSRrbRg3xjwaNTeNmC20AIS4/YkORuqQgEi1lhx8KLBDcQNi1CJTFBWykLF//uHfjsg7dc2fuPffO0/crmeydM2fm+d6d+cxz7plznm+qCknteMu0C5A0XoZaaoyhlhpjqKXGGGqpMYZaaoyhbkySO5P89rg/N8llSdYtrjr1wVDPqCRPJjlj2nXsVFV/VlUj/7JIcnCSm5O8kuSpJL86ifr0f/aadgFq3heBV4FDgeOBryd5sKoenmpVDXOmXmKSrEhyS5LnkmwbPl61225HJ/l2ku1J/i7Jwbt8/s8k+eckLyZ5MMn7O4772STXDB/vneSaJN8dfp17kxw6z+fsC/wy8Jmqermq7ga+BlywwKevDgz10vMW4CrgXcA7ge8Bf7XbPr8G/CZwGPAa8JcASVYCXwf+BDgY+EPgxiSHjFjDrwMHAocDbwd+Z1jH7n4ceK2qHt9l24PAT4w4nkZgqJeYqvpuVd1YVf9dVS8Bfwr83G67XV1VD1XVK8BngNVJlgHnA7dW1a1V9XpVbQA2Ah8esYzvMwjzj1XVjqqaq6rt8+y3H7D79v8C9h9xPI3AUC8xSfZJ8tfDk07bgbuAg4ah3enpXR4/BSwH3sFgdj9neMj8YpIXgfcxmNFHcTXwDeD6JP+R5M+TLJ9nv5eBA3bbdgDw0ojjaQSGeun5JHAs8NNVdQBw6nB7dtnn8F0ev5PBzPo8g7BfXVUH7fK2b1VdPkoBVfX9qvpcVR0H/CxwFoND/t09DuyV5Jhdtr0b8CTZBBnq2bZ8eFJq59teDA5dvwe8ODwB9sfzfN75SY5Lsg/weeCGqtoBXAP8YpJfSLJs+DXfP8+Jth8oyQeS/NTw6GA7g18ar+++3/Dw/ybg80n2TXIK8FEGM70mxFDPtlsZBHjn22eBK4C3MZh5vwXcNs/nXQ18BXgG2Bv4fYCqeppBqC4DnmMwc/8Ro/8c/ChwA4NAbwL+kTcP6u8N630WuA74Xf+cNVlxkQSpLc7UUmMMtdQYQy01xlBLjZnIDR1Jmjz7tmLFil7HW7lyZW9jbd8+3wVhk7F169bextqxY0dvY/WtqjLfdu/SGsEZZ/R7J+Tll490Tcii3H777b2Ndemll/Y21rZt23oba1Z4+C01xlBLjTHUUmMMtdQYQy01xlBLjTHUUmMMtdQYQy01plOok5yZ5LEkTyTp73IgSSPbY6iHS9Z8EfgQcBxwXpLjJl2YpIXpMlOfDDxRVZur6lXgegZL4kiaQV1CvZI3Ljm7ZbjtDZKsSbIxycZxFSdpdGO7S6uq1gJrod1bL6WloMtMvZU3riO9arhN0gzqEup7gWOSHJnkrcC5DJqcSZpBezz8rqrXknycQZuVZcCVrtssza5Or6mr6lYGC8tLmnFeUSY1xlBLjTHUUmMMtdQYQy01xlBLjTHUUmPs0DGCPjtmABx11FG9jdVnS6EXXniht7FWr17d21gA69ev73W8+ThTS40x1FJjDLXUGEMtNcZQS40x1FJjDLXUGEMtNcZQS40x1FJjunTouDLJs0ke6qMgSYvTZab+CnDmhOuQNCZ7DHVV3QX0dwW+pEUZ211aSdYAa8b19SQtjG13pMZ49ltqjKGWGtPlT1rXAf8CHJtkS5LfmnxZkhaqSy+t8/ooRNJ4ePgtNcZQS40x1FJjDLXUGEMtNcZQS40x1FJjlnzbnRNPPLG3sfpsgwNw9NFH9zbW5s2bextrw4YNvY3V588H2HZH0gQYaqkxhlpqjKGWGmOopcYYaqkxhlpqjKGWGmOopcYYaqkxXdYoOzzJHUkeSfJwkov6KEzSwnS59vs14JNVdV+S/YG5JBuq6pEJ1yZpAbq03flOVd03fPwSsAlYOenCJC3MSHdpJTkCOAG4Z56P2XZHmgGdQ51kP+BG4OKq2r77x227I82GTme/kyxnEOhrq+qmyZYkaTG6nP0O8GVgU1V9YfIlSVqMLjP1KcAFwGlJHhi+fXjCdUlaoC5td+4G0kMtksbAK8qkxhhqqTGGWmqMoZYaY6ilxhhqqTGGWmqMoZYas+R7aa1YsaK3sebm5nobC/rtb9Wnvv8ff9g4U0uNMdRSYwy11BhDLTXGUEuNMdRSYwy11BhDLTXGUEuN6bLw4N5Jvp3kwWHbnc/1UZikhelymej/AKdV1cvDpYLvTvL3VfWtCdcmaQG6LDxYwMvDd5cP31ysX5pRXRfzX5bkAeBZYENVzdt2J8nGJBvHXKOkEXQKdVXtqKrjgVXAyUl+cp591lbVSVV10phrlDSCkc5+V9WLwB3AmROpRtKidTn7fUiSg4aP3wZ8EHh0wnVJWqAuZ78PA76aZBmDXwJ/W1W3TLYsSQvV5ez3vzLoSS1pCfCKMqkxhlpqjKGWGmOopcYYaqkxhlpqjKGWGmOopcbYdmcEt99+e29jtazP79m2bdt6G2tWOFNLjTHUUmMMtdQYQy01xlBLjTHUUmMMtdQYQy01xlBLjTHUUmM6h3q4oP/9SVx0UJpho8zUFwGbJlWIpPHo2nZnFfARYN1ky5G0WF1n6iuATwGvv9kO9tKSZkOXDh1nAc9W1dwP2s9eWtJs6DJTnwKcneRJ4HrgtCTXTLQqSQu2x1BX1aeralVVHQGcC3yzqs6feGWSFsS/U0uNGWk5o6q6E7hzIpVIGgtnaqkxhlpqjKGWGmOopcYYaqkxhlpqjKGWGrPk2+702VblxBNP7G2svvXZCqfP/8f169f3NtascKaWGmOopcYYaqkxhlpqjKGWGmOopcYYaqkxhlpqjKGWGmOopcZ0ukx0uJLoS8AO4DWXAZZm1yjXfn+gqp6fWCWSxsLDb6kxXUNdwD8kmUuyZr4dbLsjzYauh9/vq6qtSX4E2JDk0aq6a9cdqmotsBYgSY25TkkddZqpq2rr8N9ngZuBkydZlKSF69Igb98k++98DPw88NCkC5O0MF0Ovw8Fbk6yc/+/qarbJlqVpAXbY6irajPw7h5qkTQG/klLaoyhlhpjqKXGGGqpMYZaaoyhlhpjqKXGpGr8l2n3ee33UUcd1ddQbNzY770qF154YW9jnXPOOb2N1ef37KST2r31v6oy33ZnaqkxhlpqjKGWGmOopcYYaqkxhlpqjKGWGmOopcYYaqkxhlpqTKdQJzkoyQ1JHk2yKcl7J12YpIXpuu73XwC3VdWvJHkrsM8Ea5K0CHsMdZIDgVOB3wCoqleBVydblqSF6nL4fSTwHHBVkvuTrBuu//0Gtt2RZkOXUO8FvAf4UlWdALwCXLr7TlW1tqpOss2tNF1dQr0F2FJV9wzfv4FByCXNoD2GuqqeAZ5Ocuxw0+nAIxOtStKCdT37/Qng2uGZ783AxyZXkqTF6BTqqnoA8LWytAR4RZnUGEMtNcZQS40x1FJjDLXUGEMtNcZQS40x1FJjlnwvrT6tWbOm1/EuueSS3saam5vrbazVq1f3NlbL7KUl/ZAw1FJjDLXUGEMtNcZQS40x1FJjDLXUGEMtNcZQS43ZY6iTHJvkgV3etie5uIfaJC3AHtcoq6rHgOMBkiwDtgI3T7YsSQs16uH36cC/V9VTkyhG0uJ1XSJ4p3OB6+b7QJI1QL93PEj6fzrP1MM1v88G1s/3cdvuSLNhlMPvDwH3VdV/TqoYSYs3SqjP400OvSXNjk6hHrau/SBw02TLkbRYXdvuvAK8fcK1SBoDryiTGmOopcYYaqkxhlpqjKGWGmOopcYYaqkxhlpqzKTa7jwHjHp75juA58dezGxo9bn5vKbnXVV1yHwfmEioFyLJxlbv8Gr1ufm8ZpOH31JjDLXUmFkK9dppFzBBrT43n9cMmpnX1JLGY5ZmakljYKilxsxEqJOcmeSxJE8kuXTa9YxDksOT3JHkkSQPJ7lo2jWNU5JlSe5Pcsu0axmnJAcluSHJo0k2JXnvtGsa1dRfUw8bBDzOYLmkLcC9wHlV9chUC1ukJIcBh1XVfUn2B+aAX1rqz2unJH8AnAQcUFVnTbuecUnyVeCfqmrdcAXdfarqxSmXNZJZmKlPBp6oqs1V9SpwPfDRKde0aFX1naq6b/j4JWATsHK6VY1HklXAR4B1065lnJIcCJwKfBmgql5daoGG2Qj1SuDpXd7fQiM//DslOQI4AbhnyqWMyxXAp4DXp1zHuB0JPAdcNXxpsW646OaSMguhblqS/YAbgYuravu061msJGcBz1bV3LRrmYC9gPcAX6qqE4BXgCV3jmcWQr0VOHyX91cNty15SZYzCPS1VdXK8sqnAGcneZLBS6XTklwz3ZLGZguwpap2HlHdwCDkS8oshPpe4JgkRw5PTJwLfG3KNS1akjB4bbapqr4w7XrGpao+XVWrquoIBt+rb1bV+VMuayyq6hng6STHDjedDiy5E5ujNsgbu6p6LcnHgW8Ay4Arq+rhKZc1DqcAFwD/luSB4bbLqurW6ZWkDj4BXDucYDYDH5tyPSOb+p+0JI3XLBx+SxojQy01xlBLjTHUUmMMtdQYQy01xlBLjflfAMZi5I5HDooAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_idx = 0\n",
    "plt.title('Label is {label}'.format(label=mnist[\"target\"][plot_idx]))\n",
    "plt.imshow(mnist[\"images\"][plot_idx], cmap='gray')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The types and domains of the variables in that dataset can be specified by numeric values for all 64 pixels and one symbolic value for the digit.\n",
    "These variables can be either created by hand"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target[DigitType(SYM)], pixel_1_1[Numeric(NUM)], pixel_1_2[Numeric(NUM)], pixel_1_3[Numeric(NUM)], pixel_1_4[Numeric(NUM)], pixel_1_5[Numeric(NUM)], pixel_1_6[Numeric(NUM)], pixel_1_7[Numeric(NUM)], pixel_1_8[Numeric(NUM)], pixel_2_1[Numeric(NUM)], pixel_2_2[Numeric(NUM)], pixel_2_3[Numeric(NUM)], pixel_2_4[Numeric(NUM)], pixel_2_5[Numeric(NUM)], pixel_2_6[Numeric(NUM)], pixel_2_7[Numeric(NUM)], pixel_2_8[Numeric(NUM)], pixel_3_1[Numeric(NUM)], pixel_3_2[Numeric(NUM)], pixel_3_3[Numeric(NUM)], pixel_3_4[Numeric(NUM)], pixel_3_5[Numeric(NUM)], pixel_3_6[Numeric(NUM)], pixel_3_7[Numeric(NUM)], pixel_3_8[Numeric(NUM)], pixel_4_1[Numeric(NUM)], pixel_4_2[Numeric(NUM)], pixel_4_3[Numeric(NUM)], pixel_4_4[Numeric(NUM)], pixel_4_5[Numeric(NUM)], pixel_4_6[Numeric(NUM)], pixel_4_7[Numeric(NUM)], pixel_4_8[Numeric(NUM)], pixel_5_1[Numeric(NUM)], pixel_5_2[Numeric(NUM)], pixel_5_3[Numeric(NUM)], pixel_5_4[Numeric(NUM)], pixel_5_5[Numeric(NUM)], pixel_5_6[Numeric(NUM)], pixel_5_7[Numeric(NUM)], pixel_5_8[Numeric(NUM)], pixel_6_1[Numeric(NUM)], pixel_6_2[Numeric(NUM)], pixel_6_3[Numeric(NUM)], pixel_6_4[Numeric(NUM)], pixel_6_5[Numeric(NUM)], pixel_6_6[Numeric(NUM)], pixel_6_7[Numeric(NUM)], pixel_6_8[Numeric(NUM)], pixel_7_1[Numeric(NUM)], pixel_7_2[Numeric(NUM)], pixel_7_3[Numeric(NUM)], pixel_7_4[Numeric(NUM)], pixel_7_5[Numeric(NUM)], pixel_7_6[Numeric(NUM)], pixel_7_7[Numeric(NUM)], pixel_7_8[Numeric(NUM)], pixel_8_1[Numeric(NUM)], pixel_8_2[Numeric(NUM)], pixel_8_3[Numeric(NUM)], pixel_8_4[Numeric(NUM)], pixel_8_5[Numeric(NUM)], pixel_8_6[Numeric(NUM)], pixel_8_7[Numeric(NUM)], pixel_8_8[Numeric(NUM)]]\n"
     ]
    }
   ],
   "source": [
    "from jpt.learning.distributions import Numeric, SymbolicType\n",
    "from jpt.variables import NumericVariable, SymbolicVariable\n",
    "pixels = ['pixel_%s_%s' % (x1 + 1, x2 + 1) for x1 in range(8) for x2 in range(8)]\n",
    "pixels = [NumericVariable(pixel, Numeric) for pixel in pixels]\n",
    "DigitType = SymbolicType('DigitType', list(range(10)))\n",
    "label = SymbolicVariable('target', domain=DigitType)\n",
    "variables = [label] + pixels\n",
    "print(variables)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "or infer them automatically from a pandas dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target[TARGET_TYPE(NUM)], pixel_0_0[PIXEL_0_0_TYPE(NUM)], pixel_0_1[PIXEL_0_1_TYPE(NUM)], pixel_0_2[PIXEL_0_2_TYPE(NUM)], pixel_0_3[PIXEL_0_3_TYPE(NUM)], pixel_0_4[PIXEL_0_4_TYPE(NUM)], pixel_0_5[PIXEL_0_5_TYPE(NUM)], pixel_0_6[PIXEL_0_6_TYPE(NUM)], pixel_0_7[PIXEL_0_7_TYPE(NUM)], pixel_1_0[PIXEL_1_0_TYPE(NUM)], pixel_1_1[PIXEL_1_1_TYPE(NUM)], pixel_1_2[PIXEL_1_2_TYPE(NUM)], pixel_1_3[PIXEL_1_3_TYPE(NUM)], pixel_1_4[PIXEL_1_4_TYPE(NUM)], pixel_1_5[PIXEL_1_5_TYPE(NUM)], pixel_1_6[PIXEL_1_6_TYPE(NUM)], pixel_1_7[PIXEL_1_7_TYPE(NUM)], pixel_2_0[PIXEL_2_0_TYPE(NUM)], pixel_2_1[PIXEL_2_1_TYPE(NUM)], pixel_2_2[PIXEL_2_2_TYPE(NUM)], pixel_2_3[PIXEL_2_3_TYPE(NUM)], pixel_2_4[PIXEL_2_4_TYPE(NUM)], pixel_2_5[PIXEL_2_5_TYPE(NUM)], pixel_2_6[PIXEL_2_6_TYPE(NUM)], pixel_2_7[PIXEL_2_7_TYPE(NUM)], pixel_3_0[PIXEL_3_0_TYPE(NUM)], pixel_3_1[PIXEL_3_1_TYPE(NUM)], pixel_3_2[PIXEL_3_2_TYPE(NUM)], pixel_3_3[PIXEL_3_3_TYPE(NUM)], pixel_3_4[PIXEL_3_4_TYPE(NUM)], pixel_3_5[PIXEL_3_5_TYPE(NUM)], pixel_3_6[PIXEL_3_6_TYPE(NUM)], pixel_3_7[PIXEL_3_7_TYPE(NUM)], pixel_4_0[PIXEL_4_0_TYPE(NUM)], pixel_4_1[PIXEL_4_1_TYPE(NUM)], pixel_4_2[PIXEL_4_2_TYPE(NUM)], pixel_4_3[PIXEL_4_3_TYPE(NUM)], pixel_4_4[PIXEL_4_4_TYPE(NUM)], pixel_4_5[PIXEL_4_5_TYPE(NUM)], pixel_4_6[PIXEL_4_6_TYPE(NUM)], pixel_4_7[PIXEL_4_7_TYPE(NUM)], pixel_5_0[PIXEL_5_0_TYPE(NUM)], pixel_5_1[PIXEL_5_1_TYPE(NUM)], pixel_5_2[PIXEL_5_2_TYPE(NUM)], pixel_5_3[PIXEL_5_3_TYPE(NUM)], pixel_5_4[PIXEL_5_4_TYPE(NUM)], pixel_5_5[PIXEL_5_5_TYPE(NUM)], pixel_5_6[PIXEL_5_6_TYPE(NUM)], pixel_5_7[PIXEL_5_7_TYPE(NUM)], pixel_6_0[PIXEL_6_0_TYPE(NUM)], pixel_6_1[PIXEL_6_1_TYPE(NUM)], pixel_6_2[PIXEL_6_2_TYPE(NUM)], pixel_6_3[PIXEL_6_3_TYPE(NUM)], pixel_6_4[PIXEL_6_4_TYPE(NUM)], pixel_6_5[PIXEL_6_5_TYPE(NUM)], pixel_6_6[PIXEL_6_6_TYPE(NUM)], pixel_6_7[PIXEL_6_7_TYPE(NUM)], pixel_7_0[PIXEL_7_0_TYPE(NUM)], pixel_7_1[PIXEL_7_1_TYPE(NUM)], pixel_7_2[PIXEL_7_2_TYPE(NUM)], pixel_7_3[PIXEL_7_3_TYPE(NUM)], pixel_7_4[PIXEL_7_4_TYPE(NUM)], pixel_7_5[PIXEL_7_5_TYPE(NUM)], pixel_7_6[PIXEL_7_6_TYPE(NUM)], pixel_7_7[PIXEL_7_7_TYPE(NUM)]]\n"
     ]
    }
   ],
   "source": [
    "from jpt.variables import infer_from_dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(data= np.c_[mnist['data'], mnist['target']],\n",
    "                     columns=['target'] + mnist['feature_names'])\n",
    "variables = infer_from_dataframe(df)\n",
    "print(variables)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see all variables got loaded correctly. Since the target variable is technically speaking a numeric variable we need to change the variable for our purposes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target[DigitType(SYM)], pixel_0_0[PIXEL_0_0_TYPE(NUM)], pixel_0_1[PIXEL_0_1_TYPE(NUM)], pixel_0_2[PIXEL_0_2_TYPE(NUM)], pixel_0_3[PIXEL_0_3_TYPE(NUM)], pixel_0_4[PIXEL_0_4_TYPE(NUM)], pixel_0_5[PIXEL_0_5_TYPE(NUM)], pixel_0_6[PIXEL_0_6_TYPE(NUM)], pixel_0_7[PIXEL_0_7_TYPE(NUM)], pixel_1_0[PIXEL_1_0_TYPE(NUM)], pixel_1_1[PIXEL_1_1_TYPE(NUM)], pixel_1_2[PIXEL_1_2_TYPE(NUM)], pixel_1_3[PIXEL_1_3_TYPE(NUM)], pixel_1_4[PIXEL_1_4_TYPE(NUM)], pixel_1_5[PIXEL_1_5_TYPE(NUM)], pixel_1_6[PIXEL_1_6_TYPE(NUM)], pixel_1_7[PIXEL_1_7_TYPE(NUM)], pixel_2_0[PIXEL_2_0_TYPE(NUM)], pixel_2_1[PIXEL_2_1_TYPE(NUM)], pixel_2_2[PIXEL_2_2_TYPE(NUM)], pixel_2_3[PIXEL_2_3_TYPE(NUM)], pixel_2_4[PIXEL_2_4_TYPE(NUM)], pixel_2_5[PIXEL_2_5_TYPE(NUM)], pixel_2_6[PIXEL_2_6_TYPE(NUM)], pixel_2_7[PIXEL_2_7_TYPE(NUM)], pixel_3_0[PIXEL_3_0_TYPE(NUM)], pixel_3_1[PIXEL_3_1_TYPE(NUM)], pixel_3_2[PIXEL_3_2_TYPE(NUM)], pixel_3_3[PIXEL_3_3_TYPE(NUM)], pixel_3_4[PIXEL_3_4_TYPE(NUM)], pixel_3_5[PIXEL_3_5_TYPE(NUM)], pixel_3_6[PIXEL_3_6_TYPE(NUM)], pixel_3_7[PIXEL_3_7_TYPE(NUM)], pixel_4_0[PIXEL_4_0_TYPE(NUM)], pixel_4_1[PIXEL_4_1_TYPE(NUM)], pixel_4_2[PIXEL_4_2_TYPE(NUM)], pixel_4_3[PIXEL_4_3_TYPE(NUM)], pixel_4_4[PIXEL_4_4_TYPE(NUM)], pixel_4_5[PIXEL_4_5_TYPE(NUM)], pixel_4_6[PIXEL_4_6_TYPE(NUM)], pixel_4_7[PIXEL_4_7_TYPE(NUM)], pixel_5_0[PIXEL_5_0_TYPE(NUM)], pixel_5_1[PIXEL_5_1_TYPE(NUM)], pixel_5_2[PIXEL_5_2_TYPE(NUM)], pixel_5_3[PIXEL_5_3_TYPE(NUM)], pixel_5_4[PIXEL_5_4_TYPE(NUM)], pixel_5_5[PIXEL_5_5_TYPE(NUM)], pixel_5_6[PIXEL_5_6_TYPE(NUM)], pixel_5_7[PIXEL_5_7_TYPE(NUM)], pixel_6_0[PIXEL_6_0_TYPE(NUM)], pixel_6_1[PIXEL_6_1_TYPE(NUM)], pixel_6_2[PIXEL_6_2_TYPE(NUM)], pixel_6_3[PIXEL_6_3_TYPE(NUM)], pixel_6_4[PIXEL_6_4_TYPE(NUM)], pixel_6_5[PIXEL_6_5_TYPE(NUM)], pixel_6_6[PIXEL_6_6_TYPE(NUM)], pixel_6_7[PIXEL_6_7_TYPE(NUM)], pixel_7_0[PIXEL_7_0_TYPE(NUM)], pixel_7_1[PIXEL_7_1_TYPE(NUM)], pixel_7_2[PIXEL_7_2_TYPE(NUM)], pixel_7_3[PIXEL_7_3_TYPE(NUM)], pixel_7_4[PIXEL_7_4_TYPE(NUM)], pixel_7_5[PIXEL_7_5_TYPE(NUM)], pixel_7_6[PIXEL_7_6_TYPE(NUM)], pixel_7_7[PIXEL_7_7_TYPE(NUM)]]\n"
     ]
    }
   ],
   "source": [
    "variables[0] = label\n",
    "print(variables)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before training a model we should talk about the hyperparameters and their influences on the model. Additionally, to the variables one can specify targets, min_samples_leaf, min_impurity_improvement and variable_dependencies.\n",
    "The targets specify the variables which impurity shall be decreased.\n",
    "On the target values no splits will be calculated.\n",
    "min_samples_leaf specifies the minimal amount of samples that are required to form a leaf.\n",
    "This is the most important hyperparameter since it constraints the complexity and accuracy that can be achieved by the tree. min_impurity_improvement specifies how much purity needs to be achieved by a split to be considered for the tree. variable_dependenciesis a map that states for every variable all dependent variables. This will guide the search in a way that impurity improvements are only measured among dependent variables. This can be used to reduce the runtime of the training process for large amounts of training data in high dimensions.\n",
    "\n",
    "To now specify a tree we will set the min_samples_leaf parameter to 100."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 09:50:33 -   INFO   - Preprocessing data...\n",
      "2022-05-09 09:50:38 -   INFO   - Data transformation... 1797 x 65\n",
      "2022-05-09 09:50:38 -   INFO   - Learning prior distributions...\n",
      "2022-05-09 09:50:38 -   INFO   - Prior distributions learnt in 0:00:00.041147.\n",
      "2022-05-09 09:50:38 -   INFO   - Started learning of 1797 x 65 at 2022-05-09 09:50:38.908408 requiring at least 100 samples per leaf\n",
      "2022-05-09 09:50:38 -   INFO   - Learning is generative. \n",
      "2022-05-09 09:50:39 -   INFO   - Learning took 0:00:00.347191\n"
     ]
    }
   ],
   "source": [
    "from jpt.trees import JPT\n",
    "\n",
    "tree = JPT(variables=variables, min_samples_leaf=100)\n",
    "tree.learn(data=df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One now may be interested in inferring probabilities from the tree.\n",
    "For example, given that the digit is a 0 the probability distributions of all pixels can be inferred with"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VariableMap {pixel_0_0: <jpt.trees.ExpectationResult object at 0x7fabe5e70970>,pixel_0_1: <jpt.trees.ExpectationResult object at 0x7fabe5e70a30>,pixel_0_2: <jpt.trees.ExpectationResult object at 0x7fabe5e70df0>,pixel_0_3: <jpt.trees.ExpectationResult object at 0x7fabe5e7a4f0>,pixel_0_4: <jpt.trees.ExpectationResult object at 0x7fabe5e7abb0>,pixel_0_5: <jpt.trees.ExpectationResult object at 0x7fabe5e0e2b0>,pixel_0_6: <jpt.trees.ExpectationResult object at 0x7fabe5e0e970>,pixel_0_7: <jpt.trees.ExpectationResult object at 0x7fabe5e0eeb0>,pixel_1_0: <jpt.trees.ExpectationResult object at 0x7fabe5e11250>,pixel_1_1: <jpt.trees.ExpectationResult object at 0x7fabe5e113d0>,pixel_1_2: <jpt.trees.ExpectationResult object at 0x7fabe5e11a90>,pixel_1_3: <jpt.trees.ExpectationResult object at 0x7fabe5e0f190>,pixel_1_4: <jpt.trees.ExpectationResult object at 0x7fabe5e0f850>,pixel_1_5: <jpt.trees.ExpectationResult object at 0x7fabe5e0ff10>,pixel_1_6: <jpt.trees.ExpectationResult object at 0x7fac0914e5b0>,pixel_1_7: <jpt.trees.ExpectationResult object at 0x7fac0914ec10>,pixel_2_0: <jpt.trees.ExpectationResult object at 0x7fac0914ef10>,pixel_2_1: <jpt.trees.ExpectationResult object at 0x7fac0914f0d0>,pixel_2_2: <jpt.trees.ExpectationResult object at 0x7fac0914f730>,pixel_2_3: <jpt.trees.ExpectationResult object at 0x7fac0914fdf0>,pixel_2_4: <jpt.trees.ExpectationResult object at 0x7fac091514f0>,pixel_2_5: <jpt.trees.ExpectationResult object at 0x7fac09151bb0>,pixel_2_6: <jpt.trees.ExpectationResult object at 0x7fac091522b0>,pixel_2_7: <jpt.trees.ExpectationResult object at 0x7fac09152910>,pixel_3_0: <jpt.trees.ExpectationResult object at 0x7fac09152c10>,pixel_3_1: <jpt.trees.ExpectationResult object at 0x7fac09152d30>,pixel_3_2: <jpt.trees.ExpectationResult object at 0x7fac091533d0>,pixel_3_3: <jpt.trees.ExpectationResult object at 0x7fac09153a30>,pixel_3_4: <jpt.trees.ExpectationResult object at 0x7fabe5f47130>,pixel_3_5: <jpt.trees.ExpectationResult object at 0x7fabe5f477f0>,pixel_3_6: <jpt.trees.ExpectationResult object at 0x7fabe5f47eb0>,pixel_3_7: <jpt.trees.ExpectationResult object at 0x7fabe5f694f0>,pixel_4_0: <jpt.trees.ExpectationResult object at 0x7fabe5f69670>,pixel_4_1: <jpt.trees.ExpectationResult object at 0x7fabe5f696d0>,pixel_4_2: <jpt.trees.ExpectationResult object at 0x7fabe5f69cd0>,pixel_4_3: <jpt.trees.ExpectationResult object at 0x7fabe5f423d0>,pixel_4_4: <jpt.trees.ExpectationResult object at 0x7fabe5f42a90>,pixel_4_5: <jpt.trees.ExpectationResult object at 0x7fabe5f55190>,pixel_4_6: <jpt.trees.ExpectationResult object at 0x7fabe5f557f0>,pixel_4_7: <jpt.trees.ExpectationResult object at 0x7fabe5f55e50>,pixel_5_0: <jpt.trees.ExpectationResult object at 0x7fabe5f55eb0>,pixel_5_1: <jpt.trees.ExpectationResult object at 0x7fabe5f610d0>,pixel_5_2: <jpt.trees.ExpectationResult object at 0x7fabe5f61730>,pixel_5_3: <jpt.trees.ExpectationResult object at 0x7fabe5f61d90>,pixel_5_4: <jpt.trees.ExpectationResult object at 0x7fabe5f6c370>,pixel_5_5: <jpt.trees.ExpectationResult object at 0x7fabe5f6ca30>,pixel_5_6: <jpt.trees.ExpectationResult object at 0x7fabd9c18130>,pixel_5_7: <jpt.trees.ExpectationResult object at 0x7fabd9c18790>,pixel_6_0: <jpt.trees.ExpectationResult object at 0x7fabd9c18970>,pixel_6_1: <jpt.trees.ExpectationResult object at 0x7fabd9c18af0>,pixel_6_2: <jpt.trees.ExpectationResult object at 0x7fabd9c2b0d0>,pixel_6_3: <jpt.trees.ExpectationResult object at 0x7fabd9c2b790>,pixel_6_4: <jpt.trees.ExpectationResult object at 0x7fabd9c2bdf0>,pixel_6_5: <jpt.trees.ExpectationResult object at 0x7fabd9c304f0>,pixel_6_6: <jpt.trees.ExpectationResult object at 0x7fabd9c30bb0>,pixel_6_7: <jpt.trees.ExpectationResult object at 0x7fabd9c1b250>,pixel_7_0: <jpt.trees.ExpectationResult object at 0x7fabd9c1b610>,pixel_7_1: <jpt.trees.ExpectationResult object at 0x7fabd9c1b730>,pixel_7_2: <jpt.trees.ExpectationResult object at 0x7fabd9c1bb50>,pixel_7_3: <jpt.trees.ExpectationResult object at 0x7fabd9c2e1f0>,pixel_7_4: <jpt.trees.ExpectationResult object at 0x7fabd9c2e8b0>,pixel_7_5: <jpt.trees.ExpectationResult object at 0x7fabd9c2ef70>,pixel_7_6: <jpt.trees.ExpectationResult object at 0x7fabd9c00670>,pixel_7_7: <jpt.trees.ExpectationResult object at 0x7fabd9c00cd0>}>\n"
     ]
    }
   ],
   "source": [
    "evidence = {variables[0]:0}\n",
    "result = tree.expectation(variables=variables[1:],evidence=evidence)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Furthermore the plotting method may be interesting. Sadly this doesnt work with jupyter notebooks since the plots are written to disk.\n",
    "Anyways the plots can be generated with tree.plot(plotvars=tree.variables)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}